
## Pay attention to the formatting, newlines, and ### delimiting- specifically for INSTRUCT models
INITIAL_PROMPT_TMPL = (
    """### Instruction:  

     Given the context below, answer the following query: "{question}"
     
     Context: {context_str}           

    ### Response:

    """
)

CONSOLIDATE_ANSWERS_PROMPT_TMPL = (
    """### Instruction:

    Given the question: "{question}"
    
    Provide a single consolidated answer to the question by considering the following list of completions generated by another AI. 
    The final answer should be concise, to the point, and take into account any relevant data presented in the completions. 
    Ensure that the final answer does not contain duplicate or extraneous information that does not contribute to the consolidated answer.
    
    Other Completions:
    \n\t- {answers}    
    
    ### Response:

     """
)

PRE_PROCESS_QUERY_PROMPT_TMPL = (
    """### Instruction:

    Given the search term "{question}", 
    please organize the search terms in order of priority, providing a comma-delimited list.

    Example search term and response:

    Search term: Please tell me which meetings Mr. Jack Smith participated in durring 2022, and tell me what involvement he had.
    Response: Jack Smith, 2022, meetings, participated, involvement
    
    ### Response:

     """
)

## Old pre processing... this works, but it does not return items in priority order.  
# This is not that great. 
# If I want to optimize search results prior to using the llm, I should implement something better.
# PRE_PROCESS_QUERY_PROMPT_TMPL = (
#     """### Instruction:

#     Using the following statement, extract key search terms and answer with a comma separated list of those terms ONLY:  
    
#     "{question}"    

#     Remember that you should answer only with comma delimited values, for example:

#     "Value 1, value2, ValueThree, Etc."

#     ### Response:

#     """
# )